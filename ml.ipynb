{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "valid_data = pd.read_csv('data/dev.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('data/test.tsv', sep='\\t') \n",
    "x_train, y_train = train_data.text_a.values, train_data.label.values # 训练集\n",
    "x_valid, y_valid = valid_data.text_a.values, valid_data.label.values # 验证集\n",
    "x_test, y_test = test_data.text_a.values, test_data.label.values # 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\86180\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.731 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 分词\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cut_words(text):\n",
    "    return ' '.join(jieba.cut(text))\n",
    "\n",
    "x_train = [cut_words(text) for text in x_train]\n",
    "x_valid = [cut_words(text) for text in x_valid]\n",
    "x_test = [cut_words(text) for text in x_test]\n",
    "\n",
    "# tf-idf\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_valid = vectorizer.transform(x_valid)\n",
    "x_test = vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use other ml model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# use more model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8954    0.8970    0.8962       592\n",
      "           1     0.8995    0.8980    0.8988       608\n",
      "\n",
      "    accuracy                         0.8975      1200\n",
      "   macro avg     0.8975    0.8975    0.8975      1200\n",
      "weighted avg     0.8975    0.8975    0.8975      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "print(\"svm:\")\n",
    "clf_SVC = SVC(kernel='linear')\n",
    "clf_SVC.fit(x_train, y_train)\n",
    "report_svm = classification_report(y_test, clf_SVC.predict(x_test),digits=4)\n",
    "print(report_svm)\n",
    "print(\"___________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8821    0.8716    0.8768       592\n",
      "           1     0.8764    0.8865    0.8814       608\n",
      "\n",
      "    accuracy                         0.8792      1200\n",
      "   macro avg     0.8792    0.8791    0.8791      1200\n",
      "weighted avg     0.8792    0.8792    0.8792      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "print(\"naive bayes:\")\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(x_train, y_train)\n",
    "report_nb = classification_report(y_test, clf_NB.predict(x_test),digits=4)\n",
    "print(report_nb)\n",
    "print(\"___________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losgistic regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8853    0.8868    0.8861       592\n",
      "           1     0.8896    0.8882    0.8889       608\n",
      "\n",
      "    accuracy                         0.8875      1200\n",
      "   macro avg     0.8875    0.8875    0.8875      1200\n",
      "weighted avg     0.8875    0.8875    0.8875      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "print(\"losgistic regression:\")\n",
    "clf_LR = LogisticRegression()\n",
    "clf_LR.fit(x_train, y_train)\n",
    "report_lr = classification_report(y_test, clf_LR.predict(x_test),digits=4)\n",
    "print(report_lr)\n",
    "print(\"___________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8792    0.9223    0.9002       592\n",
      "           1     0.9206    0.8766    0.8981       608\n",
      "\n",
      "    accuracy                         0.8992      1200\n",
      "   macro avg     0.8999    0.8995    0.8992      1200\n",
      "weighted avg     0.9002    0.8992    0.8991      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "print(\"random forest:\")\n",
    "clf_RF = RandomForestClassifier()\n",
    "clf_RF.fit(x_train, y_train)\n",
    "report_rf = classification_report(y_test, clf_RF.predict(x_test),digits=4)\n",
    "print(report_rf)\n",
    "print(\"___________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7938    0.8260    0.8096       592\n",
      "           1     0.8236    0.7911    0.8070       608\n",
      "\n",
      "    accuracy                         0.8083      1200\n",
      "   macro avg     0.8087    0.8086    0.8083      1200\n",
      "weighted avg     0.8089    0.8083    0.8083      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "print(\"decision tree:\")\n",
    "clf_DT = DecisionTreeClassifier()\n",
    "clf_DT.fit(x_train, y_train)\n",
    "report_dt = classification_report(y_test, clf_DT.predict(x_test),digits=4)\n",
    "print(report_dt)\n",
    "print(\"___________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7694    0.8057    0.7871       592\n",
      "           1     0.8017    0.7648    0.7828       608\n",
      "\n",
      "    accuracy                         0.7850      1200\n",
      "   macro avg     0.7855    0.7853    0.7850      1200\n",
      "weighted avg     0.7858    0.7850    0.7849      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "print(\"adaboost:\")\n",
    "clf_AdB = AdaBoostClassifier()\n",
    "clf_AdB.fit(x_train, y_train)\n",
    "report_ada = classification_report(y_test, clf_AdB.predict(x_test),digits=4)\n",
    "print(report_ada)\n",
    "print(\"___________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7763    0.8851    0.8272       592\n",
      "           1     0.8705    0.7516    0.8067       608\n",
      "\n",
      "    accuracy                         0.8175      1200\n",
      "   macro avg     0.8234    0.8184    0.8169      1200\n",
      "weighted avg     0.8240    0.8175    0.8168      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GradientBoosting\n",
    "print(\"gradient boosting:\")\n",
    "clf_GB = GradientBoostingClassifier()\n",
    "clf_GB.fit(x_train, y_train)\n",
    "report_gb = classification_report(y_test, clf_GB.predict(x_test),digits=4)\n",
    "print(report_gb)\n",
    "print(\"___________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8918    0.9054    0.8986       592\n",
      "           1     0.9065    0.8931    0.8998       608\n",
      "\n",
      "    accuracy                         0.8992      1200\n",
      "   macro avg     0.8992    0.8992    0.8992      1200\n",
      "weighted avg     0.8993    0.8992    0.8992      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "print(\"sgd:\")\n",
    "clf_SGD = SGDClassifier()\n",
    "clf_SGD.fit(x_train, y_train)\n",
    "report_sgd = classification_report(y_test, clf_SGD.predict(x_test),digits=4)\n",
    "print(report_sgd)\n",
    "print(\"___________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7887    0.8953    0.8386       592\n",
      "           1     0.8826    0.7664    0.8204       608\n",
      "\n",
      "    accuracy                         0.8300      1200\n",
      "   macro avg     0.8356    0.8309    0.8295      1200\n",
      "weighted avg     0.8363    0.8300    0.8294      1200\n",
      "\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "print(\"bagging:\")\n",
    "clf_BG = BaggingClassifier()\n",
    "clf_BG.fit(x_train, y_train)\n",
    "report_bag = classification_report(y_test, clf_BG.predict(x_test),digits=4)\n",
    "print(report_bag)\n",
    "print(\"___________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the information of every report from above like precision, recall, f1-score, accuracy and make a table\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_report(report):\n",
    "    report = report.split(\"\\n\")\n",
    "    res = []\n",
    "    for i in report:\n",
    "        i = re.sub(\" +\", \" \", i.strip())\n",
    "        temp = i.split(\" \")\n",
    "        res.append(temp[1:])\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_df(report):\n",
    "    res = get_report(report)\n",
    "    acc = float(res[5][0])\n",
    "    precision = float(res[6][1])\n",
    "    recall = float(res[6][2])\n",
    "    f1 = float(res[6][3])\n",
    "    return  [acc, precision, recall, f1]\n",
    "\n",
    "svm_df = get_df(report_svm)\n",
    "lr_df = get_df(report_lr)\n",
    "nb_df = get_df(report_nb)\n",
    "rf_df = get_df(report_rf)\n",
    "dt_df = get_df(report_dt)\n",
    "ada_df = get_df(report_ada)\n",
    "gb_df = get_df(report_gb)\n",
    "sgd_df = get_df(report_sgd)\n",
    "bag_df = get_df(report_bag)\n",
    "df = pd.DataFrame([svm_df, lr_df, nb_df, rf_df,  dt_df, ada_df, gb_df, sgd_df, bag_df],\n",
    "                    columns=['accuracy', 'precision', 'recall', 'f1-score'],\n",
    "                    index=['svm', 'lr', 'nb', 'rf', 'dt', 'ada', 'gb',  'sgd', 'bag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.8875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.8083</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.8083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>0.7850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.8169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bag</th>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.8356</td>\n",
       "      <td>0.8309</td>\n",
       "      <td>0.8295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  precision  recall  f1-score\n",
       "svm    0.8975     0.8975  0.8975    0.8975\n",
       "lr     0.8875     0.8875  0.8875    0.8875\n",
       "nb     0.8792     0.8792  0.8791    0.8791\n",
       "rf     0.8992     0.8999  0.8995    0.8992\n",
       "dt     0.8083     0.8087  0.8086    0.8083\n",
       "ada    0.7850     0.7855  0.7853    0.7850\n",
       "gb     0.8175     0.8234  0.8184    0.8169\n",
       "sgd    0.8992     0.8992  0.8992    0.8992\n",
       "bag    0.8300     0.8356  0.8309    0.8295"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-> neg   |   1-> pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1], [0, 1], [0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 0]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# use rf model to predict the test data\n",
    "\n",
    "sen = ['这什么垃圾酒店', '很棒的酒店']\n",
    "\n",
    "def predict(sent,clf):\n",
    "    X = [cut_words(sent)]\n",
    "    X = vectorizer.transform(X)\n",
    "    if type(sent) == str:\n",
    "        return clf.predict(X)[0]\n",
    "    else:\n",
    "        result = []\n",
    "        for i in range(len(sent)):\n",
    "            result.append(clf.predict(X[i])[0])\n",
    "        return result\n",
    "\n",
    "def predict_muti(sen,clf_list):\n",
    "    X = [cut_words(text) for text in sen]\n",
    "    X = vectorizer.transform(X)\n",
    "    result = []\n",
    "    for clf in clf_list:\n",
    "        res = []\n",
    "        for i in range(len(sen)):\n",
    "            res.append(clf.predict(X[i])[0])\n",
    "        result.append(res)\n",
    "    return result\n",
    "\n",
    "model_list = [clf_SVC, clf_NB, clf_LR, clf_RF, clf_DT, clf_AdB, clf_GB, clf_SGD,clf_BG]\n",
    "print(predict_muti(sen,model_list))\n",
    "print(predict(sen[0],clf_RF))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
