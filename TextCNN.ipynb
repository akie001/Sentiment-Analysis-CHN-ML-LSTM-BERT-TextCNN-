{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 安装依赖库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "valid_data = pd.read_csv('data/dev.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('data/test.tsv', sep='\\t') \n",
    "x_train, y_train = train_data.text_a.values, train_data.label.values # 训练集\n",
    "x_valid, y_valid = valid_data.text_a.values, valid_data.label.values # 验证集\n",
    "x_test, y_test = test_data.text_a.values, test_data.label.values # 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>房间太小。其他的都一般。。。。。。。。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>1</td>\n",
       "      <td>看过该书，感觉中医暂时不会消亡，尚有一、二十株老树活着，还有毛以林、黄煌、刘力红等一批有一定...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>0</td>\n",
       "      <td>这本书没读到底，不是特别喜欢。完全可以用序中的评价来表达我的感受：可以包容，却不想实践。除了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>1</td>\n",
       "      <td>虽是观景房,不过我住的楼层太低(19楼)看不到江景,但地点很好,离轻轨临江门站和较场口站(起...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>1</td>\n",
       "      <td>性价比不错，交通方便。行政楼层感觉很好，只是早上8点楼上装修，好吵。 中餐厅档次太低，虽然便...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9145</th>\n",
       "      <td>0</td>\n",
       "      <td>跟心灵鸡汤没什么本质区别嘛，至少我不喜欢这样读经典，把经典都解读成这样有点去中国化的味道了</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             text_a\n",
       "0         1  选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全...\n",
       "1         1  15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很...\n",
       "2         0                               房间太小。其他的都一般。。。。。。。。。\n",
       "3         0  1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸...\n",
       "4         1  今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量...\n",
       "...     ...                                                ...\n",
       "9141      1  看过该书，感觉中医暂时不会消亡，尚有一、二十株老树活着，还有毛以林、黄煌、刘力红等一批有一定...\n",
       "9142      0  这本书没读到底，不是特别喜欢。完全可以用序中的评价来表达我的感受：可以包容，却不想实践。除了...\n",
       "9143      1  虽是观景房,不过我住的楼层太低(19楼)看不到江景,但地点很好,离轻轨临江门站和较场口站(起...\n",
       "9144      1  性价比不错，交通方便。行政楼层感觉很好，只是早上8点楼上装修，好吵。 中餐厅档次太低，虽然便...\n",
       "9145      0      跟心灵鸡汤没什么本质区别嘛，至少我不喜欢这样读经典，把经典都解读成这样有点去中国化的味道了\n",
       "\n",
       "[9146 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n",
       "        '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错',\n",
       "        '房间太小。其他的都一般。。。。。。。。。', ...,\n",
       "        '虽是观景房,不过我住的楼层太低(19楼)看不到江景,但地点很好,离轻轨临江门站和较场口站(起点)很近,解放碑就在附近(大约100多公尺吧)!',\n",
       "        '性价比不错，交通方便。行政楼层感觉很好，只是早上8点楼上装修，好吵。 中餐厅档次太低，虽然便宜，但是和酒店档次不相配。',\n",
       "        '跟心灵鸡汤没什么本质区别嘛，至少我不喜欢这样读经典，把经典都解读成这样有点去中国化的味道了'], dtype=object),\n",
       " array([1, 1, 0, ..., 1, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 构建词汇表"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改1： 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\86180\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.612 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words : \n",
      "[('，', 53056), ('的', 36867), ('。', 20583), ('了', 13389), ('是', 9424), (',', 8162), ('我', 8160), ('很', 6124), ('！', 5411), ('也', 5158), ('在', 4576), ('酒店', 4312), ('不', 4242), ('都', 4110), ('有', 4100), ('就', 3695), ('.', 3681), ('没有', 3197), ('还', 3098), ('房间', 3077)] \n",
      "\n",
      "--------------------text after dropping the stopwords --------------------\n",
      "Total number: 9146\n",
      "Average length: 36.85928274655587\n",
      "Max length: 13236\n",
      "Min length: 0\n",
      "Most common words : \n",
      "[('酒店', 4312), ('没有', 3197), ('房间', 3077), ('不错', 2666), ('说', 2135), ('本书', 1860), ('一个', 1848), ('感觉', 1818), ('比较', 1690), ('买', 1681), ('服务', 1601), ('书', 1522), ('住', 1487), ('非常', 1378), ('喜欢', 1192), ('入住', 1191), ('!', 1164), ('没', 1146), ('会', 1119), ('知道', 959)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = set()\n",
    "cut_docs = [\" \".join(jieba.cut(x)) for x in train_data.text_a.values]\n",
    "cut_docs = list(cut_docs)\n",
    "print(\"Most common words : \\n{} \\n\".format(Counter(\" \".join(cut_docs).split()).most_common(20)))\n",
    "\n",
    "# 创建停用词列表\n",
    "stopword_path = 'data/chinese_stopwords.txt'\n",
    "def get_stop_words():\n",
    "    stopwords = [line.strip() for line in open(stopword_path, encoding='UTF-8').readlines()]\n",
    "    stopwords += [\",\", \"'\"]\n",
    "    return stopwords\n",
    "stopwords = get_stop_words()\n",
    "\n",
    "# 去除停用词\n",
    "segs_without_stop = []\n",
    "for sentence in cut_docs:\n",
    "    sentWords = [x.strip() for x in sentence.split(' ') if x.strip() and x.strip() not in stopwords]\n",
    "    segs_without_stop.append(' '.join(sentWords))\n",
    "\n",
    "for doc in segs_without_stop:\n",
    "    for word in doc:\n",
    "        if word.strip():\n",
    "            vocab.add(word.strip())\n",
    "\n",
    "segs = segs_without_stop\n",
    "print('-' * 20 + 'text after dropping the stopwords ' + '-' * 20)\n",
    "print(\"Total number: {}\".format(len(segs)))\n",
    "print(\"Average length: {}\".format(np.mean([len(sentence.split()) for sentence in segs])))\n",
    "print(\"Max length: {}\".format(np.max([len(sentence.split()) for sentence in segs])))\n",
    "print(\"Min length: {}\".format(np.min([len(sentence.split()) for sentence in segs])))\n",
    "text_seg = \" \".join(segs)\n",
    "c = Counter(text_seg.split()).most_common(20)\n",
    "print(\"Most common words : \\n{} \\n\".format(c))\n",
    "\n",
    "# 将词表写入本地vocab.txt文件\n",
    "with open('data/vocab.txt', 'w') as file:\n",
    "    for word in  vocab:\n",
    "        file.write(word)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4221"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the percentage of text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(text) for text in segs], bins=50 , range=(0,500), density=True)\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Percentage of Texts')\n",
    "# draw a line in 200 and calculate the percentage below 200\n",
    "plt.axvline(x=200, c='red')\n",
    "plt.text(220, 0.008, 'Percentage below 200: {:.2f}%'.format(len([len(text) for text in segs if len(text) <= 200])/len(segs)*100))\n",
    "# draw a line in 300 and calculate the percentage below 300\n",
    "plt.axvline(x=300, c='green')\n",
    "plt.text(220, 0.006, 'Percentage below 300: {:.2f}%'.format(len([len(text) for text in segs if len(text) <= 300])/len(segs)*100))\n",
    "# draw a line in 400 and calculate the percentage below 400\n",
    "plt.axvline(x=400, c='yellow')\n",
    "plt.text(220, 0.004, 'Percentage below 400: {:.2f}%'.format(len([len(text) for text in segs if len(text) <= 400])/len(segs)*100))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 定义配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    embedding_dim = 500 # 词向量维度\n",
    "    max_seq_len = 400 # 文章最大词数\n",
    "    vocab_file = 'data/vocab.txt' # 词汇表文件路径\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 定义预处理类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        # 初始化词和id的映射词典，预留0给padding字符，1给词表中未见过的词\n",
    "        token2idx = {\"[PAD]\": 0, \"[UNK]\": 1} # {word：id}\n",
    "        with open(config.vocab_file, 'r') as reader:\n",
    "            for index, line in enumerate(reader):\n",
    "                token = line.strip()\n",
    "                token2idx[token] = index + 2 # 从2开始编号\n",
    "                \n",
    "        self.token2idx = token2idx\n",
    "        \n",
    "    def transform(self, text_list):\n",
    "        # 去除停用词\n",
    "        segs_without_stop = []\n",
    "        for sentence in text_list:\n",
    "            sentence = re.sub(r'[^\\u4e00-\\u9fa5]+',' ',sentence)\n",
    "            sentWords = [x.strip() for x in sentence.split(' ') if x.strip() and x.strip() not in stopwords]\n",
    "            segs_without_stop.append(' '.join(sentWords))\n",
    "        # 文本分词，并将词转换成相应的id, 最后不同长度的文本padding长统一长度，后面补0\n",
    "        idx_list = [[self.token2idx.get(word.strip(), self.token2idx['[UNK]']) for word in text] for text in segs_without_stop]\n",
    "        # for i in range(len(idx_list)):\n",
    "        #     # print其idx和对应的词\n",
    "        #     print(idx_list[i], [list(self.token2idx.keys())[list(self.token2idx.values()).index(idx)] for idx in idx_list[i]])\n",
    "        idx_padding = pad_sequences(idx_list, self.config.max_seq_len, padding='post')\n",
    "        \n",
    "        return idx_padding\n",
    "# 以上使用了one-hot编码，实现了词向量的转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3703,  656,  450, 2457, 3997,    1, 1967, 2261, 3888, 1120,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [1776,  879, 1763,   70,    1, 4111, 2922, 3110, 1618, 1305, 1143,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor(config)\n",
    "preprocessor.transform(['性价比不错，交通方便。', '房间太小。其他的都一般。'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 定义模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.preprocessor = Preprocessor(config)\n",
    "        self.class_name = {0: '负面', 1: '正面'}\n",
    "    \n",
    "    def build_model(self):\n",
    "        # 模型架构搭建\n",
    "        idx_input = tf.keras.layers.Input((self.config.max_seq_len,))\n",
    "        input_embedding = tf.keras.layers.Embedding(len(self.preprocessor.token2idx),\n",
    "                    self.config.embedding_dim,\n",
    "                    input_length = self.config.max_seq_len,\n",
    "                    mask_zero = True)(idx_input)\n",
    "        convs = []\n",
    "        for kernel_size in [2,3,4]:\n",
    "            c = tf.keras.layers.Conv1D(128, kernel_size, activation='relu')(input_embedding)\n",
    "            c = tf.keras.layers.GlobalMaxPooling1D()(c)\n",
    "            convs.append(c)\n",
    "        fea_cnn = tf.keras.layers.Concatenate()(convs)\n",
    "        fea_cnn_dropout = tf.keras.layers.Dropout(rate=0.5)(fea_cnn)\n",
    "        \n",
    "        fea_dense = tf.keras.layers.Dense(128, activation='relu')(fea_cnn_dropout)\n",
    "        output = tf.keras.layers.Dense(2, activation='softmax')(fea_dense)\n",
    "        \n",
    "        model = tf.keras.Model(inputs=idx_input, outputs=output)\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, x_train, y_train, x_valid=None, y_valid=None, epochs=5, batch_size=128, callbacks=None, **kwargs):\n",
    "        # 训练\n",
    "        self.build_model()\n",
    "        \n",
    "        x_train = self.preprocessor.transform(x_train)\n",
    "        valid_data = None\n",
    "        if x_valid is not None and y_valid is not None:\n",
    "            x_valid = self.preprocessor.transform(x_valid)\n",
    "            valid_data = (x_valid, y_valid)\n",
    "\n",
    "        self.model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            validation_data= valid_data,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        # 评估\n",
    "        x_test = self.preprocessor.transform(x_test)\n",
    "        y_pred_probs = self.model.predict(x_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=-1)\n",
    "        result = classification_report(y_test, y_pred, target_names=['负面', '正面'],digits=4)\n",
    "        print(result)\n",
    "        \n",
    "        \n",
    "    def single_predict(self, text):\n",
    "        # 预测\n",
    "        input_idx = self.preprocessor.transform([text])\n",
    "        predict_prob = self.model.predict(input_idx)[0]\n",
    "        predict_label_id = np.argmax(predict_prob)\n",
    "        \n",
    "        predict_label_name = self.class_name[predict_label_id]\n",
    "        predict_label_prob = predict_prob[predict_label_id]\n",
    "        \n",
    "        return predict_label_name, predict_label_prob\n",
    "    \n",
    "    def load_model(self, ckpt_file):\n",
    "        self.build_model()\n",
    "        self.model.load_weights(ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 400, 500)     2111500     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 399, 128)     128128      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 398, 128)     192128      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 397, 128)     256128      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 384)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            258         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,737,422\n",
      "Trainable params: 2,737,422\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "72/72 [==============================] - 13s 83ms/step - loss: 0.5154 - accuracy: 0.7367 - val_loss: 0.3515 - val_accuracy: 0.8583\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.3225 - accuracy: 0.8722 - val_loss: 0.2975 - val_accuracy: 0.8858\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.2119 - accuracy: 0.9225 - val_loss: 0.2724 - val_accuracy: 0.9008\n",
      "Epoch 4/50\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.2747 - val_accuracy: 0.9042\n",
      "Epoch 5/50\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.1022 - accuracy: 0.9637 - val_loss: 0.2760 - val_accuracy: 0.9100\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.0792 - accuracy: 0.9759 - val_loss: 0.2970 - val_accuracy: 0.9083\n",
      "Epoch 7/50\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.0684 - accuracy: 0.9775 - val_loss: 0.3314 - val_accuracy: 0.9017\n",
      "Epoch 8/50\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 0.3313 - val_accuracy: 0.9092\n",
      "Epoch 9/50\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.3503 - val_accuracy: 0.9033\n"
     ]
    }
   ],
   "source": [
    "# 定义early stop早停回调函数\n",
    "patience = 6\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "# 定义checkpoint回调函数\n",
    "checkpoint_prefix = './checkpoints/textcnn_ckpt'\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True)\n",
    "\n",
    "# 初始化模型类，启动训练\n",
    "textcnn = TextCNN(config)\n",
    "textcnn.fit(x_train, y_train, x_valid, y_valid, epochs=50, callbacks=[early_stop, checkpoint_callback]) # 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 测试评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          负面     0.9347    0.8953    0.9146       592\n",
      "          正面     0.9021    0.9391    0.9202       608\n",
      "\n",
      "    accuracy                         0.9175      1200\n",
      "   macro avg     0.9184    0.9172    0.9174      1200\n",
      "weighted avg     0.9182    0.9175    0.9174      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textcnn.evaluate(x_test, y_test) # 测试集评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 离线加载预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 400, 500)     2111500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 399, 128)     128128      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 398, 128)     192128      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 397, 128)     256128      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " global_max_pooling1d_3 (Global  (None, 128)         0           ['conv1d_3[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_4 (Global  (None, 128)         0           ['conv1d_4[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_5 (Global  (None, 128)         0           ['conv1d_5[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 384)          0           ['global_max_pooling1d_3[0][0]', \n",
      "                                                                  'global_max_pooling1d_4[0][0]', \n",
      "                                                                  'global_max_pooling1d_5[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 384)          0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          49280       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            258         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,737,422\n",
      "Trainable params: 2,737,422\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "textcnn = TextCNN(config)\n",
    "textcnn.load_model(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          负面     0.8900    0.9155    0.9026       592\n",
      "          正面     0.9154    0.8898    0.9024       608\n",
      "\n",
      "    accuracy                         0.9025      1200\n",
      "   macro avg     0.9027    0.9027    0.9025      1200\n",
      "weighted avg     0.9029    0.9025    0.9025      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textcnn.evaluate(x_test, y_test) # 测试集评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('正面', 0.9995352)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcnn.single_predict(\"外观很漂亮，出人意料地漂亮，做工非常好\") # 单句预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('负面', 0.9998235)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcnn.single_predict(\"书的内容没什么好说的，主要是纸张、印刷太差，所用的纸非常粗糙比一般的盗版书还要差，裁的也不好。\") # 单句预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用全集进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          负面     0.7223    0.9439    0.8184      2444\n",
      "          正面     0.9700    0.8333    0.8965      5322\n",
      "\n",
      "    accuracy                         0.8681      7766\n",
      "   macro avg     0.8462    0.8886    0.8574      7766\n",
      "weighted avg     0.8921    0.8681    0.8719      7766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd_all = pd.read_csv('data/ChnSentiCorp_htl_all.csv').astype(str) \n",
    "\n",
    "# test model on ChnSentiCorp_htl_all\n",
    "x_all = pd_all['review'].tolist()\n",
    "y_all = pd_all['label'].tolist()\n",
    "y_all = list(map(int, y_all))\n",
    "textcnn.evaluate(x_all, y_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5491c76d3edf9cb98dfc60b1bf8e535b737aeb9467f129549e75183f4d432829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
